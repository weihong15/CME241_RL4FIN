{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "## Markov Process\n",
    "\n",
    "A *Markov Process* consists of :\n",
    "\n",
    "1. A countable set of states $\\mathcal{S}$ (known as the State Space) and a set $\\mathcal{T} \\subset \\mathcal{S}$ (known as the set of Terminal States\n",
    "2. A time-indexed sequence of random states $S_t \\in \\mathcal{S}$ for all time steps, each satisfying Markov Property\n",
    "3. *Termination*: If an outcome for $S_T$ (for some time step T) is a state in the set $\\mathcal{T}$, then this sequence outcome terminates at time step T.\n",
    "\n",
    "We refer to $\\mathbb{P}[S_{t+1}|S_t]$ as the transition probabilities for time t\n",
    "\n",
    "## Stationary Markov Process\n",
    "A *Stationary Markov Process* is a MP with the additional property that $\\mathbb{P}[S_{t+1}|S_t]$ is independent of $t$.\n",
    "\n",
    "This means, the dynamics of a Stationary Markov Process can be fully specified with the function\n",
    "\\begin{equation}\n",
    "\\mathcal{P}:(\\mathcal{S}-\\mathcal{T}) \\times \\mathcal{S} \\rightarrow [0,1]\n",
    "\\end{equation}\n",
    "such that $\\mathcal{P}(s0,s1)=\\mathbb{P}[S_{t+1}=s1|S_t=s0]$\n",
    "\n",
    "## Finite Markov Process\n",
    "MP with finite state spaces. Note that we now can express our transition in a fixed matrix(fixed num rows, and cols).\n",
    "The matrix if often sparse, we can represent it as a dictionary of dictionary\n",
    "\\begin{equation}\n",
    "\\mathcal{P} :\\mathcal{N}\\times \\mathcal{S}\\rightarrow [0,1] \\\\\n",
    "\\mathcal{N} \\rightarrow (\\mathcal{S} \\rightarrow [0,1])\n",
    "\\end{equation}\n",
    "Equivalently. `Transition = Mapping[S, Optional[FiniteDistribution[S]]]`\n",
    "\n",
    "## Stationary Distribution of MP\n",
    "The *Stationary Distribution* of a (Stationary) Markov Process with state space $\\mathcal{S}=\\mathcal{N}$ and transition probability function $\\mathcal{P}:\\mathcal{N}\\times \\mathcal{N} \\rightarrow [0,1]$ is a probability distribution function $\\pi: \\mathcal{N}\\rightarrow [0,1]$ s.t.\n",
    "\\begin{equation}\n",
    "\\pi (s) = \\sum_{s'\\in \\mathcal{N}} \\pi(s) \\cdot \\mathcal{P}(s',s) \\text{for all $s\\in\\mathcal{N}$}\n",
    "\\end{equation}\n",
    "The intuitive meaning is, in the long run, if there's no terminal state, the probabilities of occurance at that state.\n",
    "\\begin{align}\n",
    "& \\pi^T = \\pi^T \\cdot \\mathcal{P} \\\\\n",
    "\\text{equivalently, } & \\mathcal{P}^T\\cdot \\pi = \\pi\n",
    "\\end{align}\n",
    "We notice that $\\pi$ is an eigenvector of $\\mathcal{P}^T$ with eigenvalue 1\n",
    "\n",
    "## Markov Reward Process\n",
    "A *Markov Reward Process* is a MP, along with time-indexed sequence of *Reward* random variables $R_t \\in\\mathbb{R}$ for time steps $t=1,2,...$ satisfying the Markov Property(including Rewards) i.e. $(R_{t},S_t)$ satisfies the MP\n",
    "\\begin{equation}\n",
    "\\mathcal{P}_R :\\mathcal{N}\\times \\mathbb{R} \\times \\mathcal{S}\\rightarrow [0,1] \\\\\n",
    "\\sum_{s'\\in\\mathcal{S}}\\sum_{r\\in\\mathbb{R}}\\mathcal{P}_R(s,r,s')=1 \\quad \\text{for all $s\\in\\mathcal{N}$}\n",
    "\\end{equation}\n",
    "\n",
    "With $\\mathcal{P}_R$ completely derived, we can calculate the following two functions\n",
    "* we can calculate $\\mathcal{P} :\\mathcal{N}\\times \\mathcal{S}\\rightarrow [0,1]$.\n",
    "\\begin{equation}\n",
    "\\mathcal{P}(s,s') = \\sum_{r\\in\\mathbb{R}} \\mathcal{P}_R(s,r,s')\n",
    "\\end{equation}\n",
    "* The reward transition function\n",
    "\\begin{equation}\n",
    "\\mathcal{R}_T: \\mathcal{N} \\times \\mathcal{S} \\rightarrow \\mathbb{R}\\\\\n",
    "\\mathcal{R}_T(s,s') = \\mathbb{E}[R_{t+1}|S_{t+1}=s',S_t=s] = \\sum_{r\\in\\mathbb{R}} \\frac{\\mathcal{P}_R(s,r,s')}{\\mathcal{P}(s,s')} r\n",
    "\\end{equation}\n",
    "\n",
    "* Reward function\n",
    "\\begin{equation}\n",
    "\\mathcal{R}:\\mathcal{N}\\rightarrow \\mathbb{R}\\\\\n",
    "\\mathcal{R}(s)=\\mathbb{E}(R_{t+1}|S_t=s)=\\sum_{s'\\in\\mathbb{S}} \\mathcal{P}(s,s')\\cdot \\mathcal{R}_T(s,s') = \\sum_{s'\\in\\mathbb{S}} \\sum_{r\\in\\mathbb{R}} \\mathcal{P}_R(s,r,s') \\cdot r\n",
    "\\end{equation}\n",
    "\n",
    "## Value function of MRP\n",
    "* Return \n",
    "\\begin{equation}\n",
    "G_t = \\sum_{i=t+1}^\\infty \\gamma^{i-t-1} \\cdot R_i = R_{t+1} + \\gamma \\cdot R_{t+2} + \\gamma^2 R_{t+3} + \\dots\n",
    "\\end{equation}\n",
    "* Value function\n",
    "\\begin{equation}\n",
    "V : \\mathcal{N}\\rightarrow \\mathbb{R}\\\\\n",
    "V(s) = \\mathbb{E}[G_t|S_t=s] \\quad \\text{for all $s\\in\\mathcal{N}$, for all $t=0,1,2,\\dots$} \\\\\n",
    "= \\mathcal{R}(S) + \\gamma \\cdot \\sum_{s'\\in\\mathcal{N}}\\mathcal{P}(s,s')\\cdot V(s') \\text{for all $s \\in \\mathcal{N}$}\n",
    "\\end{equation}\n",
    "\n",
    "* Matrix formulation, V = (m*1), P = (m X m) R = (m X 1)\n",
    "\\begin{equation}\n",
    "\\mathbf{V} = \\mathbf{\\mathcal{R}} + \\gamma\\mathbf{\\mathcal{P}}\\cdot\\mathbf{V} \\\\\n",
    "\\mathbf{V} = (\\mathbf{I}_m - \\gamma \\mathbf{\\mathcal{P}})^{-1}\\cdot \\mathbf{\\mathcal{R}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary\n",
    "\n",
    "1. $\\mathcal{S}$: Set of State Space\n",
    "2. $\\mathcal{T}$: Set of Terminal States\n",
    "3. $\\mathcal{N}$: Set of Non-Terminal States. $\\mathcal{N} = \\mathcal{S}-\\mathcal{T}$\n",
    "4. $\\mathcal{P}$: Transition probability function of SMP(indepedent of $t$)\n",
    "\n",
    "# G2\n",
    "* Episodic/continuing: episodic are MP that ends,i.e. SnL, Continuing is like prices of stock, fixed cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
